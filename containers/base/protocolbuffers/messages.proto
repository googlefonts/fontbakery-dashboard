syntax = "proto3";

import "google/protobuf/any.proto";
import "google/protobuf/timestamp.proto";
import "google/protobuf/empty.proto";
import public "shared.proto";

package fontbakery.dashboard;

message FamilyJob {
    string docid = 1;
    StorageKey cache_key = 2;
    //
    // START distributed job fields
    //
    // used to be int32, but the default of that is 0 which also can be
    // a valid jobid. The default of string is an empty string, better to
    // distinguish
    string jobid = 3;
    repeated string order = 4;
    //
    // END distributed job fields
    //
}


// The Storage service

service Storage {
  rpc Put (stream StorageItem) returns (stream StorageKey) {};
  // Sends another greeting
  rpc Get (StorageKey) returns (google.protobuf.Any) {};
  rpc Purge (StorageKey) returns (StorageStatus) {};
}

// The request message containing the user's name.
message StorageItem {
  google.protobuf.Any payload = 1;
  // this will be set in the response StorageKey of [PUT]
  // so the client of the streaming interface can  match it's
  // request to the responses
  string clientid = 2;
}

message StorageKey {
    // always set
    string key = 1;
    // optional, returned by PUT, not needed for GET or PURGE
    // hash of the binary payload data
    string hash = 2;
    // optional, returned by PUT, not needed for GET or PURGE
    // set if StorageItem.clientid was set
    string clientid = 3;
    // optional, used for PURGE
    bool force = 4;
}

message StorageStatus {
    string key = 1;
    int32 instances = 2;
}

// The Manifest service

service Manifest {
  // FIXME: this is outdated but may have some good bits!
  // check for updates and emit a notice if since the last poke families
  // were updated
  // so if there's a change, we'll download it directly and put the files
  // ordered into a Files message. The sha256 hash is what we emit as
  // a change message ManifestKey: (manifiestid/collectionid, family name, filesHash)
  // PokeResponse, is basically nothing, just a OK message ... how to do this
  // best with grpc?
  // Maybe we could directly send this to the cache?
  // If we need to re-run an entiren Collection, because Font Bakery changed,
  // we still need the latest versions of the collection on disk.
  // so, it would be nice to have some form of atomicity between asking the
  // informing the ManifestMaster and running the tests. Therefore, we could
  // just put the entire current state into the cache and then let the
  // ManifestMaster decide which ones to keep and which ones to drop.
  // The Manifest itselt can in the meantime update itself etc.
  // I.e. We create a "Snapshot" of the manifest in the cache, then
  // we can forget about it
  rpc Poke (ManifestSourceId) returns (google.protobuf.Empty) {};
  // This is the same data as the manifestSource would dispatch as
  // CollectionFamilyJob for Font Bakery.
  rpc Get (FamilyRequest) returns (FamilyData){};
  rpc List (ManifestSourceId) returns (FamilyNamesList){};
}


message ManifestSourceId {
    string source_id = 1;
}

message FamilyNamesList {
    repeated string family_names = 1;
}

message FamilyRequest {
    string source_id = 1;
    string family_name = 2;
}

message CollectionFamilyJob {
    string collectionid = 1; // the name that identifies the collection
    string family_name = 2; // the name that identifies the family
    StorageKey cache_key = 3;
    google.protobuf.Timestamp date = 4; // when the job was created
    // We'll have more information about the job eventually
    // i.e. a "Upstream" or "PullRequests" source will likely be created
    // from different repositories. The information from what repository
    // the family actually comes is very interesting and should be included
    // This is a metadata dict stored as JSON
    string metadata = 5;
}



// TODO: this is very similar to CollectionFamilyJob, but the cache_key/files
// fields differ. Since they represent the same thing though, maybe it would
// be nice to merge the two message formats into one?
// could be a oneof data { cache_key|files }
message FamilyData {
    string collectionid = 1; // the name that identifies the collection
    string family_name = 2; // the name that identifies the family
    Files files = 3;
    google.protobuf.Timestamp date = 4; // when the data was created
    string metadata = 5;//json?
}

// The Reports service

service Reports {
  // Provides interfaces to read the data, get listings/filter.

  // to file the report ("file" as a verb, but by convention first letter uppercased)
  rpc File (Report) returns (google.protobuf.Empty) {};
  // Get a list of reports including selection/filtering etc.
  rpc Query (ReportsQuery) returns (stream Report) {};
  rpc Get (ReportIds) returns (stream Report) {};
  // Describe what filters can be used in a ReportsQuery
  // not implemented (and maybe not sound, look into ReportsServer
  // rpc Describe (google.protobuf.Empty) returns (ReportsQuery) {};

}

// A Report is be publicly available in a simple web interface.
// It's meant to have reports about the inner workings of the
// Dashboard, so that we can check if everything is running within
// expected margins or if some action is required.
message Report {
    string type = 1; // the type of the service that issued the report
    string type_id = 2; // the id of the service, expected to be unique per type
    string method = 3; // the method of the service that generated the report
    // The timestamps are nice to have e.g. to figure how long method takes
    google.protobuf.Timestamp started = 4; // when the Report was started
    google.protobuf.Timestamp finished = 5; // when the Report was finished
    // JSON serialized report data. This is underspecified on purpose ATM.
    // Expecting this to be an array of arrays, where the items contain two
    // elements: `type` and type specific data.
    // known types: "md" (markdown) "table" data to be rendered in a table
    // with some meta data added.
    string data = 6; // when reading, optionally used
    // Not used when writing, only when reading:
    string id = 7; // database id, if existing => not used when saving a new report
    google.protobuf.Timestamp reported = 8; // when the Report was filed, if existing
}

message ReportsQuery {
    message Filter {
        enum Type {
            VALUE = 0;
            DATE = 1;
        };
        Type type = 1;
        // if this is a Type.VALUE type
        repeated string values = 2;
        // if this is a Type.DATE type
        // if more than one, pick min and max
        repeated google.protobuf.Timestamp min_max_dates = 3;
    };
    // filter name -> reportFilter
    map<string, Filter> filters = 1;
    message Pagination {
      google.protobuf.Timestamp item_reported = 1;
      string item_id = 2;
      bool previous_page = 3;
    };
    Pagination pagination = 4;
    bool include_data = 5;
}

message ReportIds {
    repeated string ids = 1;
}

// The Process Manager service ...

service ProcessManager {
  // returns the current Process state initially and on each change of
  // the Process state a new Process
  rpc SubscribeProcess (ProcessQuery) returns (stream ProcessState) {};
  // same as SubscribeProcess but only returns the current state once
  rpc GetProcess (ProcessQuery) returns (ProcessState) {};
  // issue a state change for a Process. `ticket` will be used to make
  // sure only expected commands are executed.
  rpc Execute (ProcessCommand) returns (ProcessCommandResult) {};
  // the any will have to unpack to a specific message defined in the
  // ProcessManagerImplementation. e.g. DispatcherProcessManager will
  // expect here a DispatcherInitProcess
  // this may also be part of making it possible to create different
  // kinds of processes in the same process manager.
  // but right now we only deal with one process implementation at a time!
  rpc InitProcess (google.protobuf.Any) returns (ProcessCommandResult) {};
  rpc GetInitProcessUi (google.protobuf.Empty) returns (ProcessState) {};
}

// This service is added next to the ProcessManager service, it
// implements specific interfaces for the Font Bakery DispatcherProcessManager
// In this case things that can't be done without specific knowledge about
// how the specific process implementation (FamilyPRDispatcherProcess)
// is stored in the database and thus, how to query them.
// FamilyPRDispatcherProcess adds an important "family" name key to it's
// state which is used as a secondary key in the database and has no
// semantic/use in other implementations.
service DispatcherProcessManager {
  // returns the ProcessList for the current query and then an updated
  // ProcessList when the list changes.
  rpc SubscribeProcessList (ProcessListQuery) returns (stream ProcessList) {};
}

message ProcessCommandResult {
    enum Result {
        FAIL = 0;
        OK = 1;
    };
    Result result = 1;
    string message = 2; // string/not set
    // could add maybe structured data (JSON) for special cases
    // but then again, in these cases the message field can transport
    // the data.
}

// whatever we need to get a dispatcher process rolling!
message DispatcherInitProcess {
    string requester = 1; // for authorization etc.
    string json_payload = 2;
}

message ProcessQuery {
    string process_id = 1;
}

message ProcessState {
  string process_id = 1;
  // JSON serialized actual process data
  string process_data = 2;
  // JSON required user interaction descriptions
  // i.e. a structure that allows us to build forms for user interactions
  string user_interface = 3;
}

message ProcessListQuery {
    string query = 1;// TODO!
}

message ProcessListItem {
  string process_id = 1;
  // TODO ...
}

message ProcessList {
    // TODO!
    repeated ProcessListItem processes = 6;
}

message ProcessCommand {
    string ticket = 1;
    string target_path = 2;
    string callback_name = 3;
    string requester = 4; // for authorization if needed
    string response_queue_name = 5;
    oneof payload {
      // This way we can do better structured protobuf messages OR
      // faster to initially implemented JSON.
      string json_payload = 6;
      google.protobuf.Any pb_payload = 7;
    }
    string session_id = 8; // e.g. to get the GitHub oAuthToken from AuthService
}

///////
// Authorization/GitHub OAuth stuff
///////

service AuthService {
  // **authentication**
  rpc InitSession (google.protobuf.Empty) returns (AuthStatus) {};
  rpc Logout (SessionId) returns (google.protobuf.Empty) {};
  // named like this due to the OAuth workflow
  rpc Authorize (AuthorizeRequest) returns (AuthStatus) {};
  rpc CheckSession (SessionId) returns (AuthStatus) {};
  //
  // **authorization** (could be another service)
  rpc GetRoles (AuthorizedRolesRequest) returns (AuthorizedRoles) {};
  rpc GetOAuthToken (SessionId) returns (OAuthToken) {};
}

message AuthStatus {
    enum StatusCode {
        ERROR = 0;
        OK = 1;
        INITIAL = 2;
        NOT_READY = 3;
        NO_SESSION = 4;
        WRONG_AUTHORIZE_STATE = 5;
        TIMED_OUT = 6;
    };
    // always
    StatusCode status = 1;
    // only if OK or INITIAL
    string session_id = 2;
    // only if INITIAL
    string authorize_url = 3;
    // only if *not* OK or INITIAL,
    // To help the user finding out what
    // went wrong. Otherwise, "just working"
    // authentication is enough of a message.
    string message = 4;
    // only if OK
    string user_name = 5;
    // only if OK
    string avatar_url = 6;
}

message AuthorizeRequest {
    string o_auth_code = 1;
    string session_id = 2;
    string authorize_state = 3;
}

message SessionId {
    string session_id = 1;
}

message AuthorizedRolesRequest {
    string session_id = 1;
    string repo_name_with_owner = 2;
}

message AuthorizedRoles {
    repeated string roles = 1;
    string user_name = 2;
};

message OAuthToken {
    string user_name = 1; // session.user.login
    string access_token = 2; // session.accessToken.accessToken
    string type = 3; // session.accessToken.token_type 'bearer'
    string scope = 4; // session.accessToken.scope 'user:email'
}


// The Pull Request Dispatcher service

service PullRequestDispatcher {
  // If answering directly THIS COULD TIME OUT!
  // instead, we answer with Empty and send the
  // DispatchReport message via another channel,
  // currently this is implement using an
  // AMQP queue which feeds into ProcessManager.Execute
  rpc Dispatch (PullRequest) returns (google.protobuf.Empty) {};
}

message PullRequest {
    string session_id = 1;
    // (file) data location, actually will return a FamilyData message
    string storage_key = 2;
    // "ofl/myfont"
    string target_directory = 3;
    // simple string as a title
    string p_r_message_title = 4;
    // github-markdown string
    string p_r_message_body = 5;
    // multi line string, first line and details should be
    // separated by an empty line
    string commit_message = 6;

    // to make answering easier in the PR dispatcher, this will have
    // the essentials already configured
    ProcessCommand process_command = 7;

    // we should not override already existing remote branches...
    // maybe create in here using family name and date
    // can we use also target_directory or should we add a
    // branch_name_keyword>>> best of both worlds?
    // string targetBranchName = 7;
}

message DispatchReport {
    enum Result {
        FAIL = 0;
        OK = 1;
    };
    Result status = 1;
    oneof value {
      // the url of the PR
      string p_r_url = 2;
      // an error message if the operation failed
      string error = 3;
    }
    // where is (or should have been if FAILED) the new remote branch?
    string branch_url = 4; // branch_url
    // more data?
}

service InitWorkers {
    // the message type of the answer is worker implementation dependent.
    rpc Init (WorkerDescription) returns (google.protobuf.Any) {};
}

message WorkerDescription {
    string worker_name = 1;
    // the message type of job is worker implementation dependent.
    google.protobuf.Any job = 2;
    // (optional) the way to answer once the job has finished
    ProcessCommand process_command = 3;
}

message WorkerJobDescription {
    string worker_name = 1;
    // the message type of job is worker implementation dependent.
    google.protobuf.Any job = 2;
}

// the workers dispatch this message to the AMQP queue
message CompletedWorker {
    string worker_name = 1;
    // the message type of completed_message is worker implementation dependent.
    google.protobuf.Any completed_message = 2;
}

message FontBakeryFinished {
    // probably not needed, but nice to have anyways
    string docid = 1;
    // If the report or a sub-job had any exceptions, it means
    // the job failed to finish orderly, i.e. the result is probably incomplete.
    bool finished_orderly = 2;
    string results_json = 3;
    google.protobuf.Timestamp created = 4;
    google.protobuf.Timestamp started = 5;
    google.protobuf.Timestamp finished = 6;
}
